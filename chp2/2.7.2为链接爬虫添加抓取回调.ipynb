{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: http://example.python-scraping.com\n",
      "Downloading: http://example.python-scraping.com/places/default/index/1\n",
      "Downloading: http://example.python-scraping.com/places/default/index/2\n",
      "Downloading: http://example.python-scraping.com/places/default/index/3\n",
      "Skipping http://example.python-scraping.com/places/default/index/4 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/view/Cameroon-40 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/view/Cambodia-39 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/view/Burundi-38 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/view/Burkina-Faso-37 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/view/Bulgaria-36 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/view/Brunei-35 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/view/British-Virgin-Islands-34 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/view/British-Indian-Ocean-Territory-33 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/view/Brazil-32 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/view/Bouvet-Island-31 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=/places/default/index/3 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=/places/default/index/3 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/view/Botswana-30\n",
      "http://example.python-scraping.com/places/default/view/Botswana-30 ['600,370 square kilometres', '2,029,307', 'BW', 'Botswana', 'Gaborone', 'AF', '.bw', 'BWP', 'Pula', '267', '', '', 'en-BW,tn-BW', 'ZW ZA NA ']\n",
      "Skipping http://example.python-scraping.com/places/default/edit/Botswana-30 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/NA due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/ZA due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/ZW due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/continent/AF due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=/places/default/view/Botswana-30 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=/places/default/view/Botswana-30 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/view/Bosnia-and-Herzegovina-29\n",
      "http://example.python-scraping.com/places/default/view/Bosnia-and-Herzegovina-29 ['51,129 square kilometres', '4,590,000', 'BA', 'Bosnia and Herzegovina', 'Sarajevo', 'EU', '.ba', 'BAM', 'Marka', '387', '#####', '^(\\\\d{5})$', 'bs,hr-BA,sr-BA', 'CS HR ME RS ']\n",
      "Skipping http://example.python-scraping.com/places/default/edit/Bosnia-and-Herzegovina-29 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/RS due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/ME due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/HR due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/CS due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/continent/EU due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=/places/default/view/Bosnia-and-Herzegovina-29 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=/places/default/view/Bosnia-and-Herzegovina-29 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/view/Bonaire-Saint-Eustatius-and-Saba-28\n",
      "http://example.python-scraping.com/places/default/view/Bonaire-Saint-Eustatius-and-Saba-28 ['328 square kilometres', '18,012', 'BQ', 'Bonaire, Saint Eustatius and Saba', '', 'NA', '.bq', 'USD', 'Dollar', '599', '', '', 'nl,pap,en', ' ']\n",
      "Skipping http://example.python-scraping.com/places/default/edit/Bonaire-Saint-Eustatius-and-Saba-28 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso// due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/continent/NA due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=/places/default/view/Bonaire-Saint-Eustatius-and-Saba-28 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=/places/default/view/Bonaire-Saint-Eustatius-and-Saba-28 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/view/Bolivia-27\n",
      "http://example.python-scraping.com/places/default/view/Bolivia-27 ['1,098,580 square kilometres', '9,947,418', 'BO', 'Bolivia', 'Sucre', 'SA', '.bo', 'BOB', 'Boliviano', '591', '', '', 'es-BO,qu,ay', 'PE CL PY BR AR ']\n",
      "Skipping http://example.python-scraping.com/places/default/edit/Bolivia-27 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/AR due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/BR due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/PY due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/CL due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/PE due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/continent/SA due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=/places/default/view/Bolivia-27 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=/places/default/view/Bolivia-27 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/view/Bhutan-26\n",
      "http://example.python-scraping.com/places/default/view/Bhutan-26 ['47,000 square kilometres', '699,847', 'BT', 'Bhutan', 'Thimphu', 'AS', '.bt', 'BTN', 'Ngultrum', '975', '', '', 'dz', ' ']\n",
      "Skipping http://example.python-scraping.com/places/default/edit/Bhutan-26 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/continent/AS due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=/places/default/view/Bhutan-26 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=/places/default/view/Bhutan-26 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/view/Bermuda-25\n",
      "http://example.python-scraping.com/places/default/view/Bermuda-25 ['53 square kilometres', '65,365', 'BM', 'Bermuda', 'Hamilton', 'NA', '.bm', 'BMD', 'Dollar', '+1-441', '@@ ##', '^([A-Z]{2}\\\\d{2})$', 'en-BM,pt', ' ']\n",
      "Skipping http://example.python-scraping.com/places/default/edit/Bermuda-25 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=/places/default/view/Bermuda-25 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=/places/default/view/Bermuda-25 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/view/Benin-24\n",
      "http://example.python-scraping.com/places/default/view/Benin-24 ['112,620 square kilometres', '9,056,010', 'BJ', 'Benin', 'Porto-Novo', 'AF', '.bj', 'XOF', 'Franc', '229', '', '', 'fr-BJ', 'NE TG BF NG ']\n",
      "Skipping http://example.python-scraping.com/places/default/edit/Benin-24 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/NG due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/BF due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/TG due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/NE due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=/places/default/view/Benin-24 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=/places/default/view/Benin-24 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/view/Belize-23\n",
      "http://example.python-scraping.com/places/default/view/Belize-23 ['22,966 square kilometres', '314,522', 'BZ', 'Belize', 'Belmopan', 'NA', '.bz', 'BZD', 'Dollar', '501', '', '', 'en-BZ,es', 'GT MX ']\n",
      "Skipping http://example.python-scraping.com/places/default/edit/Belize-23 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/MX due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/GT due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=/places/default/view/Belize-23 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=/places/default/view/Belize-23 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/view/Belgium-22\n",
      "http://example.python-scraping.com/places/default/view/Belgium-22 ['30,510 square kilometres', '10,403,000', 'BE', 'Belgium', 'Brussels', 'EU', '.be', 'EUR', 'Euro', '32', '####', '^(\\\\d{4})$', 'nl-BE,fr-BE,de-BE', 'DE NL LU FR ']\n",
      "Skipping http://example.python-scraping.com/places/default/edit/Belgium-22 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/FR due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/LU due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/NL due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/DE due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=/places/default/view/Belgium-22 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=/places/default/view/Belgium-22 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/view/Belarus-21\n",
      "http://example.python-scraping.com/places/default/view/Belarus-21 ['207,600 square kilometres', '9,685,000', 'BY', 'Belarus', 'Minsk', 'EU', '.by', 'BYR', 'Ruble', '375', '######', '^(\\\\d{6})$', 'be,ru', 'PL LT UA RU LV ']\n",
      "Skipping http://example.python-scraping.com/places/default/edit/Belarus-21 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/LV due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/RU due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/UA due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/LT due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/iso/PL due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=/places/default/view/Belarus-21 due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=/places/default/view/Belarus-21 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=/places/default/index/2\n",
      "Skipping http://example.python-scraping.com/places/default/user/login due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/register due to depth\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Findex%2F2 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/user/register?_next=/places/default/index/2\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=%2Fplaces%2Fdefault%2Findex%2F2 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/index/0\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=/places/default/index/0\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Findex%2F0 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/user/register?_next=/places/default/index/0\n",
      "Skipping http://example.python-scraping.com/places/default/user/register?_next=%2Fplaces%2Fdefault%2Findex%2F0 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/view/Barbados-20\n",
      "http://example.python-scraping.com/places/default/view/Barbados-20 ['431 square kilometres', '285,653', 'BB', 'Barbados', 'Bridgetown', 'NA', '.bb', 'BBD', 'Dollar', '+1-246', 'BB#####', '^(?:BB)*(\\\\d{5})$', 'en-BB', ' ']\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Barbados-20\n",
      "Skipping http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FBarbados-20 due to depth\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=/places/default/view/Barbados-20\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-9052a403d31f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mchp2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madvanced_link_crawler\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mlink_crawler\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscrape_callback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m link_crawler('http://example.python-scraping.com', '/(places|default|view)/',\n\u001B[1;32m----> 3\u001B[1;33m scrape_callback=scrape_callback)\n\u001B[0m",
      "\u001B[1;32mD:\\0ilraypan\\git_jia\\《用Python写网络爬虫2》\\chp2\\advanced_link_crawler.py\u001B[0m in \u001B[0;36mlink_crawler\u001B[1;34m(start_url, link_regex, robots_url, user_agent, proxy, delay, max_depth, scrape_callback)\u001B[0m\n\u001B[0;32m    108\u001B[0m                 \u001B[1;32mcontinue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    109\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mscrape_callback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 110\u001B[1;33m                 \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mscrape_callback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhtml\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    111\u001B[0m             \u001B[1;31m# filter for links matching our regular expression\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mlink\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mget_links\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhtml\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\git_jia\\《用Python写网络爬虫2》\\chp2\\advanced_link_crawler.py\u001B[0m in \u001B[0;36mscrape_callback\u001B[1;34m(url, html)\u001B[0m\n\u001B[0;32m     67\u001B[0m         all_rows = [\n\u001B[0;32m     68\u001B[0m             \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxpath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'//tr[@id=\"places_%s__row\"]/td[@class=\"w2p_fw\"]'\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mfield\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext_content\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 69\u001B[1;33m             for field in fields]\n\u001B[0m\u001B[0;32m     70\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mall_rows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\git_jia\\《用Python写网络爬虫2》\\chp2\\advanced_link_crawler.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     67\u001B[0m         all_rows = [\n\u001B[0;32m     68\u001B[0m             \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxpath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'//tr[@id=\"places_%s__row\"]/td[@class=\"w2p_fw\"]'\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mfield\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext_content\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 69\u001B[1;33m             for field in fields]\n\u001B[0m\u001B[0;32m     70\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mall_rows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from chp2.advanced_link_crawler import link_crawler, scrape_callback\n",
    "link_crawler('http://example.python-scraping.com', '/(places|default|view)/',\n",
    "scrape_callback=scrape_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: http://example.python-scraping.com/\n",
      "Downloading: http://example.python-scraping.com/places/default/index/1\n",
      "Downloading: http://example.python-scraping.com/places/default/index/2\n",
      "Downloading: http://example.python-scraping.com/places/default/index/3\n",
      "Downloading: http://example.python-scraping.com/places/default/index/4\n",
      "Downloading: http://example.python-scraping.com/places/default/index/5\n",
      "Downloading: http://example.python-scraping.com/places/default/index/6\n",
      "Downloading: http://example.python-scraping.com/places/default/index/7\n",
      "Downloading: http://example.python-scraping.com/places/default/index/8\n",
      "Downloading: http://example.python-scraping.com/places/default/index/9\n",
      "Downloading: http://example.python-scraping.com/places/default/index/10\n",
      "Downloading: http://example.python-scraping.com/places/default/index/11\n",
      "Downloading: http://example.python-scraping.com/places/default/index/12\n",
      "Downloading: http://example.python-scraping.com/places/default/index/13\n",
      "Downloading: http://example.python-scraping.com/places/default/index/14\n",
      "Downloading: http://example.python-scraping.com/places/default/index/15\n",
      "Downloading: http://example.python-scraping.com/places/default/index/16\n",
      "Downloading: http://example.python-scraping.com/places/default/index/17\n",
      "Downloading: http://example.python-scraping.com/places/default/index/18\n",
      "Downloading: http://example.python-scraping.com/places/default/index/19\n",
      "Downloading: http://example.python-scraping.com/places/default/index/20\n",
      "Downloading: http://example.python-scraping.com/places/default/index/21\n",
      "Downloading: http://example.python-scraping.com/places/default/index/22\n",
      "Downloading: http://example.python-scraping.com/places/default/index/23\n",
      "Downloading: http://example.python-scraping.com/places/default/index/24\n",
      "Downloading: http://example.python-scraping.com/places/default/view/Zimbabwe-246\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Zimbabwe-246\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login\n",
      "Downloading: http://example.python-scraping.com/places/default/user/register\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FZimbabwe-246\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/ZM\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Zambia-245\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FZambia-245\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/AO\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Angola-7\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FAngola-7\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/CG\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Republic-of-the-Congo-177\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FRepublic-of-the-Congo-177\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/CM\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Cameroon-40\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FCameroon-40\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/NG\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Nigeria-157\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FNigeria-157\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/BJ\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Benin-24\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FBenin-24\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/BF\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Burkina-Faso-37\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FBurkina-Faso-37\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/ML\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Mali-131\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FMali-131\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/MR\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Mauritania-135\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FMauritania-135\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/EH\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Western-Sahara-243\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FWestern-Sahara-243\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/MA\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Morocco-145\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FMorocco-145\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/ES\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Spain-208\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FSpain-208\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/FR\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/France-74\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FFrance-74\n",
      "Downloading: http://example.python-scraping.com/places/default/iso/MC\n",
      "Downloading: http://example.python-scraping.com/places/default/edit/Monaco-141\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=%2Fplaces%2Fdefault%2Fedit%2FMonaco-141\n",
      "Downloading: http://example.python-scraping.com/places/default/user/login?_next=/places/default/view/Monaco-141\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-b9effe073bcb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mchp2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcsv_callback\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mCsvCallback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m link_crawler('http://example.python-scraping.com/', '/(places|default|view)',\n\u001B[1;32m----> 4\u001B[1;33m max_depth=-1, scrape_callback=CsvCallback())\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\git_jia\\《用Python写网络爬虫2》\\chp2\\advanced_link_crawler.py\u001B[0m in \u001B[0;36mlink_crawler\u001B[1;34m(start_url, link_regex, robots_url, user_agent, proxy, delay, max_depth, scrape_callback)\u001B[0m\n\u001B[0;32m    108\u001B[0m                 \u001B[1;32mcontinue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    109\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mscrape_callback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 110\u001B[1;33m                 \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mscrape_callback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhtml\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    111\u001B[0m             \u001B[1;31m# filter for links matching our regular expression\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mlink\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mget_links\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhtml\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\git_jia\\《用Python写网络爬虫2》\\chp2\\csv_callback.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, url, html)\u001B[0m\n\u001B[0;32m     18\u001B[0m             all_rows = [\n\u001B[0;32m     19\u001B[0m                 \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxpath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'//tr[@id=\"places_%s__row\"]/td[@class=\"w2p_fw\"]'\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mfield\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext_content\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m                 for field in self.fields]\n\u001B[0m\u001B[0;32m     21\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwriter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwriterow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_rows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\git_jia\\《用Python写网络爬虫2》\\chp2\\csv_callback.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     18\u001B[0m             all_rows = [\n\u001B[0;32m     19\u001B[0m                 \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxpath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'//tr[@id=\"places_%s__row\"]/td[@class=\"w2p_fw\"]'\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mfield\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext_content\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m                 for field in self.fields]\n\u001B[0m\u001B[0;32m     21\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwriter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwriterow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_rows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "from chp2.advanced_link_crawler import link_crawler\n",
    "from chp2.csv_callback import CsvCallback\n",
    "link_crawler('http://example.python-scraping.com/', '/(places|default|view)',\n",
    "max_depth=-1, scrape_callback=CsvCallback())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-4aac85bb",
   "language": "python",
   "display_name": "PyCharm (HeiKeGongFang)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}